<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://winny-shang.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://winny-shang.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-02-06T17:03:49+00:00</updated><id>https://winny-shang.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">How and Why are different in nature</title><link href="https://winny-shang.github.io/blog/2024/How_and_Why/" rel="alternate" type="text/html" title="How and Why are different in nature"/><published>2024-01-05T00:00:00+00:00</published><updated>2024-01-05T00:00:00+00:00</updated><id>https://winny-shang.github.io/blog/2024/How_and_Why</id><content type="html" xml:base="https://winny-shang.github.io/blog/2024/How_and_Why/"><![CDATA[<blockquote> <p>When describing “how,” the focus is on reconstructing a series of events from one point leading to another. On the other hand, explaining “why” involves identifying causal relationships and understanding why a series of events occurred in a particular way rather than another. Explaining past events can be influenced by their outcomes, and interpreting why current results seem inevitable with hindsight can lead to biases.</p> <p>——《Sapiens: A Brief History of Humankind》, Yuval Harari</p> </blockquote> <h4 id="distinguishing-how-and-why"><strong>Distinguishing “How” and “Why”:</strong></h4> <p>In language, “how” questions focus on specific steps and methods to achieve a goal or reach a certain state. For example, we might ask, “How to make a cup of coffee?” This question leads us to reconstruct a sequence of events and steps to achieve the goal of making coffee.</p> <p>Conversely, “why” questions focus on the reasons or motives behind things happening. For instance, “Why does the sky turn dark?” This question delves into the fundamental reasons or factors leading to this phenomenon, involving explanations of cause and effect relationships.</p> <h4 id="application-in-computer-modeling"><strong>Application in Computer Modeling:</strong></h4> <p>In computer model training, models that focus on “how” are primarily concerned with implementing specific tasks or generating specific outputs. These models typically rely on large-scale pre-training on language data to learn language representations and patterns, tackling various natural language processing tasks such as text generation, question answering, and language understanding. While these models excel at modeling language data, they pay less attention to causal reasoning or explanations behind events.</p> <p>On the other hand, “why” models, also known as causal inference models, possess the ability to understand causal relationships. These models specialize in revealing the root causes, motives, and influencing factors behind events, offering more interpretable results. In prediction, decision support, and adversarial contexts, these models have certain advantages, providing deeper insights and guidance.</p> <h4 id="the-importance-of-why-in-history"><strong>The Importance of “Why” in History:</strong></h4> <p>History often appears inevitable in hindsight, while seeming unclear or unpredictable at the time. Emphasizing the importance of “why” in historical analysis helps us understand the fundamental reasons, motives, and influencing factors behind events.</p> <p>Analyzing historical events using “why” models can provide deeper insights, helping us better understand the development process of historical events and phenomena. By exploring the interactions between different factors, the motives behind decisions, and the background conditions of events, we can gain a more comprehensive understanding of historical events.</p> <h4 id="importance-in-computer-training"><strong>Importance in Computer Training:</strong></h4> <p>Current large-scale models (such as the GPT, BERT, etc.) tend to be “how” models, focusing on executing various natural language processing tasks. While these models excel at handling tasks, they still have limitations in terms of interpretability and reasoning ability.</p> <p>In education, emphasizing the importance of understanding “why” is crucial. Educators often remind students that selecting an answer is not as important as understanding why that answer is chosen. Through understanding the reasons and logic behind problems, students can develop deeper knowledge and skills, fostering critical thinking, problem-solving ability, and creative thinking.</p> <p>In computer training, enabling models to understand “why” is equally important. Simply training models to perform tasks or produce correct outputs is not enough. Understanding the reasons, motives, and logic behind tasks is essential for the model’s robustness, generalization ability, and interpretability.</p> <p>Through understanding the reasons and logic behind problems, models can better adapt to new situations and data, demonstrating stronger generalization ability and providing more interpretable decision processes.</p>]]></content><author><name></name></author><category term="bookreviews"/><summary type="html"><![CDATA[When describing “how,” the focus is on reconstructing a series of events from one point leading to another. On the other hand, explaining “why” involves identifying causal relationships and understanding why a series of events occurred in a particular way rather than another. Explaining past events can be influenced by their outcomes, and interpreting why current results seem inevitable with hindsight can lead to biases. ——《Sapiens: A Brief History of Humankind》, Yuval Harari]]></summary></entry><entry><title type="html">Chaotic systems and reinforcement learning</title><link href="https://winny-shang.github.io/blog/2024/Chaotic/" rel="alternate" type="text/html" title="Chaotic systems and reinforcement learning"/><published>2024-01-04T00:00:00+00:00</published><updated>2024-01-04T00:00:00+00:00</updated><id>https://winny-shang.github.io/blog/2024/Chaotic</id><content type="html" xml:base="https://winny-shang.github.io/blog/2024/Chaotic/"><![CDATA[<p>In chaos theory, chaotic systems are described as dynamical systems that exhibit nonlinearity and are sensitive to initial conditions.</p> <blockquote> <p><strong>First-order chaotic systems:</strong> These typically refer to systems exhibiting chaotic behavior, but are not sensitive to small changes in initial conditions. This means that even tiny disturbances can lead to significant deviations in the system’s trajectory, but over time, these trajectories remain consistent and do not undergo fundamental changes. A classic example is the weather system. Although weather systems are complex chaotic systems, long-term weather trends can generally be predicted reliably, despite being highly sensitive to small changes in initial conditions, which may not significantly alter the forecast results over the predictive time scale.</p> <p><strong>Second-order chaotic systems:</strong> These systems are extremely sensitive to small changes in initial conditions, and over time, this sensitivity leads to rapid divergence of the system’s trajectory, resulting in significant differences. A typical example is the logistic map. In such systems, even minor errors or disturbances can cause huge deviations in the system’s trajectory, making predictions of future behavior almost impossible.</p> <p><strong>Third-order chaotic systems:</strong> These systems exacerbate the extreme sensitivity to initial conditions seen in second-order chaotic systems. In such systems, minor variations lead to extreme divergence in trajectories, rendering long-term predictions completely unreliable.</p> </blockquote> <p>Large-scale language models such as GPT and BERT are typically designed to handle complex language data, including natural language text and language generation tasks. These models are usually used to predict problems with second-order chaotic system characteristics.</p> <p>In natural language processing, while human language and textual data do not perfectly conform to the definition of chaotic systems, they do exhibit a degree of complexity and uncertainty. Language data contains many implicit patterns and rules, but these patterns and rules are influenced by factors such as culture, context, and language habits, resulting in significant effects from minor changes in initial conditions. Therefore, natural language processing tasks can generally be considered problems with second-order chaotic system characteristics.</p> <p>GPT and BERT, among other large language models, capture this complexity and uncertainty by learning from large amounts of language data. They adapt to variations in input text to some extent, enabling them to predict and generate complex natural language texts. While these models may not fully predict complex textual contexts, they demonstrate considerable effectiveness when processing natural language data with second-order chaotic system characteristics.</p> <p>Reinforcement learning is generally more suitable for predicting or controlling systems with higher-order chaotic behavior, especially those involving complex nonlinear dynamics and multivariate interactions. Therefore, reinforcement learning is more likely to be applicable to predicting or controlling third-order chaotic systems, where systems exhibit extreme sensitivity to small changes in initial conditions, leading to extreme divergence in system trajectories.</p> <p>In reinforcement learning, an agent learns behavior strategies by interacting with the environment to maximize cumulative rewards. For complex and uncertain environments, such as third-order chaotic systems, reinforcement learning is applicable in learning strategies that adapt to environmental changes and uncertainties. Through trial and error and experience, reinforcement learning algorithms can gradually adjust their strategies to cope with environmental changes and uncertainties, achieving more effective prediction or control.</p> <p>In conclusion, while reinforcement learning may be more suitable for systems with higher-order chaotic behavior, its application is still influenced by factors such as the specific characteristics of the system, the complexity of the problem, and the availability of data and resources. Therefore, when using reinforcement learning for prediction or control, careful analysis and practical validation of specific problems are necessary.</p>]]></content><author><name></name></author><category term="bookreviews"/><summary type="html"><![CDATA[In chaos theory, chaotic systems are described as dynamical systems that exhibit nonlinearity and are sensitive to initial conditions.]]></summary></entry><entry><title type="html">Computers&amp;amp;#58 Ardent Fans of Memes</title><link href="https://winny-shang.github.io/blog/2024/Memes/" rel="alternate" type="text/html" title="Computers&amp;amp;#58 Ardent Fans of Memes"/><published>2024-01-03T00:00:00+00:00</published><updated>2024-01-03T00:00:00+00:00</updated><id>https://winny-shang.github.io/blog/2024/Memes</id><content type="html" xml:base="https://winny-shang.github.io/blog/2024/Memes/"><![CDATA[<p>When exploring the essence of computer learning, it’s essential to consider the sources of information that computers encounter and learn from, which include human behavior, thoughts, and culture. Because computers cannot learn the basic elements of human physiology, such as eating and reproduction, the content they learn may be more akin to “memes”.</p> <p>“Memes” refer to units similar to genes in cultural transmission. They are the basic units of thought, behavior, or cultural transmission. Just as genes play a crucial role in biological evolution, memes also play a similar role in cultural evolution. Memes can be a piece of text, an image, a song, or even a behavioral pattern, and they spread and influence populations through replication and transmission.</p> <p>Considering that computers primarily learn and process information from text, images, audio, and other data, they are more likely to encounter and understand memes in culture rather than basic physiological elements. Therefore, it can be argued that computers are actually learning memes, as they understand and mimic human behavior and thought by learning and analyzing information from culture.</p> <p>This perspective also helps explain the success of computers in fields such as natural language processing, image recognition, and audio processing, as these domains are rich in cultural transmission and meme content.</p> <p>There is no evidence to prove that history progresses for the benefit of humanity because there is no objective standard for benefit. Different cultures have different definitions of “good,” and there are no objective standards either. Some scholars even argue that culture is like a mental infection or parasite, and humans are unwitting hosts. Parasites or viruses reproduce and spread within hosts, depriving them of nutrients and sometimes even causing death. According to this view, culture is not a conspiracy designed by some people to exploit others, but rather a psychological parasite that began to exploit all infected individuals after appearing.</p> <p>This view is sometimes referred to as memetics. Memetics assumes that, just as biological evolution is based on genes, cultural evolution is based on memes. So-called successful cultures are those that are particularly good at replicating their memes, regardless of the cost or benefit to their human hosts, such as the development of weapons.</p> <p>So from this perspective, we cannot prove that the content learned by computers is good. :laughing:</p>]]></content><author><name></name></author><category term="bookreviews"/><summary type="html"><![CDATA[When exploring the essence of computer learning, it’s essential to consider the sources of information that computers encounter and learn from, which include human behavior, thoughts, and culture. Because computers cannot learn the basic elements of human physiology, such as eating and reproduction, the content they learn may be more akin to “memes”.]]></summary></entry><entry><title type="html">The Dopamine of Computers&amp;amp;#58 Exploring Motivation in Machine Learning</title><link href="https://winny-shang.github.io/blog/2024/Dopamine/" rel="alternate" type="text/html" title="The Dopamine of Computers&amp;amp;#58 Exploring Motivation in Machine Learning"/><published>2024-01-02T00:00:00+00:00</published><updated>2024-01-02T00:00:00+00:00</updated><id>https://winny-shang.github.io/blog/2024/Dopamine</id><content type="html" xml:base="https://winny-shang.github.io/blog/2024/Dopamine/"><![CDATA[<p>Dopamine, a neurotransmitter and chemical substance playing a vital role in the human body, regulates motivation and reward mechanisms. It aids in steering individuals towards goals and behaviors directed at achieving those objectives. Similarly, in the realm of computer modeling, dopamine’s analogy manifests as a reward or incentive signal guiding the model’s actions towards correctness or value. Typically, this signal correlates with the task objectives or problems the model faces.</p> <p>In machine learning, especially in reinforcement learning, this signal is often referred to as the reward signal. Models interact with the environment to acquire reward signals, adjusting their behaviors accordingly to maximize cumulative rewards. This reward signal, akin to dopamine in the brain, propels models to explore different actions in pursuit of optimal solutions, thus fostering a preference for actions that yield favorable outcomes.</p> <p>In supervised learning, dopamine’s analogy may align more closely with feedback signals during training. Correct predictions may elicit a “reward,” while erroneous predictions may lead to a “penalty.” This feedback incentivizes model parameter adjustments, improving predictive accuracy or classification.</p> <blockquote> <p>Looking Upwards: Dopamine, as Goal and Drive;</p> <p>Looking Downwards: Neurotransmitters Affecting Action.</p> <p>——《Greedy Dopamine》, Daniel Lieberman</p> </blockquote> <p>Looking Upwards: In deep reinforcement learning, dopamine can be compared to the objectives pursued by the model, such as maximizing cumulative rewards or achieving specific tasks. This objective drives the model towards continual optimization for optimal solutions. Dopamine signals serve as motivational cues, indicating to the model which actions to take in different states to maximize the goal of reward maximization.</p> <p>Looking Downwards: In the execution process of the model, neurotransmitters are analogous to internal factors influencing the model’s behavior. For instance, in deep neural networks, neurotransmitters can be likened to the outputs of activation functions, directly impacting the network’s decisions and behaviors. Through the action of neurotransmitters, the model can map inputs to outputs and take appropriate actions in different environments.</p> <p>Contemplating computer “motivation” has long intrigued me. In biological evolution, reproduction serves as a reward for high-fitness individuals. Drawing parallels to the computer domain, could using model rewards as a measure of adaptiveness, then training new models based on high-fitness ones, be feasible? For instance:</p> <ol> <li>Setting a reward threshold: Define a threshold where models surpassing this reward are deemed high-fitness.</li> <li>Selecting high-fitness models: Filter out high-fitness models based on rewards obtained during training.</li> <li>Training new models using high-fitness ones: Choose high-fitness models as initial training models for new ones, allowing the latter to learn features and strategies from the former.</li> <li>Further training and optimization: Use new models to train for new tasks, continually improving model performance through optimization algorithms.</li> </ol> <p>This approach might accelerate model training, particularly in reinforcement learning, leveraging the experiences and knowledge of high-fitness models to expedite the learning process for new models.</p>]]></content><author><name></name></author><category term="bookreviews"/><summary type="html"><![CDATA[Dopamine, a neurotransmitter and chemical substance playing a vital role in the human body, regulates motivation and reward mechanisms. It aids in steering individuals towards goals and behaviors directed at achieving those objectives. Similarly, in the realm of computer modeling, dopamine’s analogy manifests as a reward or incentive signal guiding the model’s actions towards correctness or value. Typically, this signal correlates with the task objectives or problems the model faces.]]></summary></entry><entry><title type="html">Will computer dreams?</title><link href="https://winny-shang.github.io/blog/2024/Dreams/" rel="alternate" type="text/html" title="Will computer dreams?"/><published>2024-01-01T00:00:00+00:00</published><updated>2024-01-01T00:00:00+00:00</updated><id>https://winny-shang.github.io/blog/2024/Dreams</id><content type="html" xml:base="https://winny-shang.github.io/blog/2024/Dreams/"><![CDATA[<p>Dreams are a mysterious and complex psychological phenomenon that has yet to be fully understood. While the exact mechanisms of dreaming are still debated in the scientific community, a common theory suggests that dreams result from the brain’s integration and interpretation of randomly generated electrical signals and memory fragments during sleep.</p> <p>If we were to analogize our everyday behaviors to computer modeling, it seems that the brain can unleash its constraints on the physical models of reality during dreams, allowing imagination and creativity to flow freely. In this state, the input data may not be bound by the physical constraints of the real world, leading to the emergence of details and scenarios not typically encountered in waking life. Some argue that dreams can be regarded as a source of creativity. During sleep, the brain operates freely, showcasing thoughts, emotions, and images that may go unnoticed or unexplored during wakefulness. Dreams often involve nonlinear, richly imaginative ideas and narratives, which can sometimes inspire creative thinking and insights.</p> <p>Many creative individuals, artists, and scientists claim to have been inspired or gained insights from their dreams. Occasionally, the visual, auditory, or emotional experiences in dreams can directly influence an individual’s creative thought process, providing new ideas, problem-solving methods, or artistic inspiration.</p> <p>In the process of training computer models, it seems that we have only focused on the “awake” aspects, such as training the model with correct, reality-conforming content, but neglected to leave room for the computer to “dream.” Similar to human dreams, introducing this “dreaming” space into the training process of computer models may lead to some unexpected and fascinating results. This nonlinear and non-logical training process could result in the emergence of novel ideas, associations between seemingly unrelated pieces of information, or even the creation of entirely new concepts or problem-solving methods.</p> <p>Moreover, dreams have a crucial characteristic: events in dreams are not subject to punishment in the “real” world, allowing for more daring actions within dreams. In the real world, training data and tasks are often subject to certain limitations and constraints, requiring models to learn and perform within these boundaries. However, within the “dreaming” space, models can be liberated to explore various bold actions and ideas without fear of real-world consequences. By introducing this unrestricted, punishment-free learning space, we can stimulate the creativity and exploratory spirit of models, enabling them to propose fresh ideas, solutions, or approaches. This method may empower models with greater flexibility and autonomy, allowing them to better tackle complex real-world problems and challenges.</p>]]></content><author><name></name></author><category term="bookreviews"/><summary type="html"><![CDATA[Dreams are a mysterious and complex psychological phenomenon that has yet to be fully understood. While the exact mechanisms of dreaming are still debated in the scientific community, a common theory suggests that dreams result from the brain’s integration and interpretation of randomly generated electrical signals and memory fragments during sleep.]]></summary></entry><entry><title type="html">Displaying External Posts on Your al-folio Blog</title><link href="https://winny-shang.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/" rel="alternate" type="text/html" title="Displaying External Posts on Your al-folio Blog"/><published>2022-04-23T23:20:09+00:00</published><updated>2022-04-23T23:20:09+00:00</updated><id>https://winny-shang.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog</id><content type="html" xml:base="https://winny-shang.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/"><![CDATA[]]></content><author><name></name></author></entry></feed>